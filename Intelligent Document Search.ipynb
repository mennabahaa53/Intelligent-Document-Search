{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6081fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import docx\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e6b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load any document\n",
    "def load_document(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \"\\n\".join(\n",
    "                page.extract_text() for page in pdf.pages if page.extract_text()\n",
    "            )\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = docx.Document(file_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    elif file_path.endswith(\".txt\"):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .pdf, .docx, or .txt\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2620f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chunk text\n",
    "def chunk_text(text, chunk_size=150):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6f17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embeddings\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_chunks(chunks):\n",
    "    return np.array(embedder.encode(chunks))\n",
    "\n",
    "def build_faiss_index(embeddings):\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "def retrieve_chunks(query, chunks, index, top_k=5):\n",
    "    query_emb = embedder.encode([query])\n",
    "    D, I = index.search(query_emb, top_k)\n",
    "    return [chunks[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2af3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# 4. Answering (use Flan-T5 for concise answers)\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "def answer_question(query, context_chunks):\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "    prompt = f\"Answer the question based on the context:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = qa_pipeline(prompt, max_new_tokens=200)\n",
    "    return response[0][\"generated_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb8f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Gradio Interface\n",
    "\n",
    "def chat_with_doc(file, question):\n",
    "    # Load document\n",
    "    text = load_document(file.name)\n",
    "    # Chunk\n",
    "    chunks = chunk_text(text)\n",
    "    # Embed + Index\n",
    "    embeddings = embed_chunks(chunks)\n",
    "    index = build_faiss_index(embeddings)\n",
    "    # Retrieve + Answer\n",
    "    retrieved_chunks = retrieve_chunks(question, chunks, index)\n",
    "    answer = answer_question(question, retrieved_chunks)\n",
    "    return answer\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ðŸ“˜ Chat with Your Document\")\n",
    "    with gr.Row():\n",
    "        file_input = gr.File(label=\"Upload Document\", type=\"filepath\")\n",
    "    question_input = gr.Textbox(label=\"Ask a Question\")\n",
    "    answer_output = gr.Textbox(label=\"Answer\")\n",
    "    btn = gr.Button(\"Get Answer\")\n",
    "    btn.click(chat_with_doc, inputs=[file_input, question_input], outputs=answer_output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739a61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f012319b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
